{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/iris.data', header=None)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df1.iloc[:, :-1]\n",
    "labels = df1[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = le.transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtclf = DecisionTreeClassifier()\n",
    "dtclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtclf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  1.0\n",
      "Accuracy Score of Test Set: 0.9\n",
      "F1 Score of Test Set: 0.9\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.91      0.91      0.91        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 7  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  2 10]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, dtclf.predict(X_train))}\")\n",
    "\n",
    "y_pred_dtclf = dtclf.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_dtclf)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_dtclf, average='weighted')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_dtclf))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_dtclf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "    \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "    \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dtclf,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 3, 5, 7, 9, 11, 12],\n",
       "                         'max_leaf_nodes': [None, 10, 20, 30, 40, 50, 60, 70,\n",
       "                                            80, 90],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'max_leaf_nodes': None, 'min_samples_leaf': 2}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333334"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9916666666666667\n",
      "Accuracy Score of Test Set: 0.9\n",
      "F1 Score of Test Set: 0.9\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.91      0.91      0.91        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 7  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  2 10]]\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_bestNB, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.tab.txt', delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = diabetes.loc[:, diabetes.columns != 'SEX']\n",
    "labels = diabetes['SEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2, random_state=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclf1 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtclf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  1.0\n",
      "Accuracy Score of Test Set: 0.6404494382022472\n",
      "F1 Score of Test Set: 0.6404494382022472\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.68      0.67        47\n",
      "           2       0.62      0.60      0.61        42\n",
      "\n",
      "    accuracy                           0.64        89\n",
      "   macro avg       0.64      0.64      0.64        89\n",
      "weighted avg       0.64      0.64      0.64        89\n",
      "\n",
      "Confusion Matrix: \n",
      " [[32 17]\n",
      " [15 25]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, dtclf1.predict(X_train))}\")\n",
    "\n",
    "y_pred_dtclf1 = dtclf1.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_dtclf1)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_dtclf1, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_dtclf1))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_dtclf1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "    \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "    \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dtclf1,\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='f1_micro',\n",
    "                            cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 3, 5, 7, 9, 11, 12],\n",
       "                         'max_leaf_nodes': [None, 10, 20, 30, 40, 50, 60, 70,\n",
       "                                            80, 90],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'max_leaf_nodes': 10, 'min_samples_leaf': 6}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.7790368271954674\n",
      "Accuracy Score of Test Set: 0.6179775280898876\n",
      "F1 Score of Test Set: 0.6179775280898876\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.62      0.63        47\n",
      "           2       0.59      0.62      0.60        42\n",
      "\n",
      "    accuracy                           0.62        89\n",
      "   macro avg       0.62      0.62      0.62        89\n",
      "weighted avg       0.62      0.62      0.62        89\n",
      "\n",
      "Confusion Matrix: \n",
      " [[29 16]\n",
      " [18 26]]\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_bestNB, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/breast-cancer-wisconsin.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[6] != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1: -1]\n",
    "y = data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace(2, 0)\n",
    "y = y.replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtclf2 = DecisionTreeClassifier()\n",
    "dtclf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  1.0\n",
      "Accuracy Score of Test Set: 0.9635036496350365\n",
      "F1 Score of Test Set: 0.9634135086932353\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        89\n",
      "           1       0.96      0.94      0.95        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "Confusion Matrix: \n",
      " [[87  3]\n",
      " [ 2 45]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, dtclf2.predict(X_train))}\")\n",
    "\n",
    "y_pred_dtclf2 = dtclf2.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_dtclf2)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_dtclf2, average='weighted')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_dtclf2))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_dtclf2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "    \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "    \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dtclf2,\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='f1',\n",
    "                            cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 3, 5, 7, 9, 11, 12],\n",
       "                         'max_leaf_nodes': [None, 10, 20, 30, 40, 50, 60, 70,\n",
       "                                            80, 90],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11, 'max_leaf_nodes': 80, 'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  1.0\n",
      "Accuracy Score of Test Set: 0.9708029197080292\n",
      "F1 Score of Test Set: 0.9708029197080292\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        89\n",
      "           1       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "Confusion Matrix: \n",
      " [[87  2]\n",
      " [ 2 46]]\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_bestNB, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
