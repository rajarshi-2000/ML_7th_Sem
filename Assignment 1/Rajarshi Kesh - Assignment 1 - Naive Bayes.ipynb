{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title: Iris Plants Database\n",
      "\tUpdated Sept 21 by C.Blake - Added discrepency information\n",
      "\n",
      "2. Sources:\n",
      "     (a) Creator: R.A. Fisher\n",
      "     (b) Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "     (c) Date: July, 1988\n",
      "\n",
      "3. Past Usage:\n",
      "   - Publications: too many to mention!!!  Here are a few.\n",
      "   1. Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "      Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions\n",
      "      to Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   2. Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "      (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   3. Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "      Structure and Classification Rule for Recognition in Partially Exposed\n",
      "      Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "      Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "      -- Results:\n",
      "         -- very low misclassification rates (0% for the setosa class)\n",
      "   4. Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE \n",
      "      Transactions on Information Theory, May 1972, 431-433.\n",
      "      -- Results:\n",
      "         -- very low misclassification rates again\n",
      "   5. See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al's AUTOCLASS II\n",
      "      conceptual clustering system finds 3 classes in the data.\n",
      "\n",
      "4. Relevant Information:\n",
      "   --- This is perhaps the best known database to be found in the pattern\n",
      "       recognition literature.  Fisher's paper is a classic in the field\n",
      "       and is referenced frequently to this day.  (See Duda & Hart, for\n",
      "       example.)  The data set contains 3 classes of 50 instances each,\n",
      "       where each class refers to a type of iris plant.  One class is\n",
      "       linearly separable from the other 2; the latter are NOT linearly\n",
      "       separable from each other.\n",
      "   --- Predicted attribute: class of iris plant.\n",
      "   --- This is an exceedingly simple domain.\n",
      "   --- This data differs from the data presented in Fishers article\n",
      "\t(identified by Steve Chadwick,  spchadwick@espeedaz.net )\n",
      "\tThe 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\"\n",
      "\twhere the error is in the fourth feature.\n",
      "\tThe 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\"\n",
      "\twhere the errors are in the second and third features.  \n",
      "\n",
      "5. Number of Instances: 150 (50 in each of three classes)\n",
      "\n",
      "6. Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "\n",
      "7. Attribute Information:\n",
      "   1. sepal length in cm\n",
      "   2. sepal width in cm\n",
      "   3. petal length in cm\n",
      "   4. petal width in cm\n",
      "   5. class: \n",
      "      -- Iris Setosa\n",
      "      -- Iris Versicolour\n",
      "      -- Iris Virginica\n",
      "\n",
      "8. Missing Attribute Values: None\n",
      "\n",
      "Summary Statistics:\n",
      "\t         Min  Max   Mean    SD   Class Correlation\n",
      "   sepal length: 4.3  7.9   5.84  0.83    0.7826   \n",
      "    sepal width: 2.0  4.4   3.05  0.43   -0.4194\n",
      "   petal length: 1.0  6.9   3.76  1.76    0.9490  (high!)\n",
      "    petal width: 0.1  2.5   1.20  0.76    0.9565  (high!)\n",
      "\n",
      "9. Class Distribution: 33.3% for each of 3 classes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/iris.names\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/iris.data\", names=col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:, 0:4]\n",
    "labels = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "label_encoder.fit(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label_encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9333333333333333\n",
      "Accuracy Score of Test Set: 0.9\n",
      "F1 Score of Test Set: 0.899248120300752\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.75      1.00      0.86         9\n",
      "           2       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.92      0.91      0.90        30\n",
      "weighted avg       0.93      0.90      0.90        30\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  9  3]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, MultiNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_MNB = MultiNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_MNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_MNB, average='weighted')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_MNB))\n",
    "\n",
    "print(confusion_matrix(y_pred_MNB, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BernNB = BernoulliNB()\n",
    "BernNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_BNB = BernNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.3416666666666667\n",
      "Accuracy Score of Test Set: 0.3\n",
      "F1 Score of Test Set: 0.3\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.30      1.00      0.46         9\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.10      0.33      0.15        30\n",
      "weighted avg       0.09      0.30      0.14        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, BernNB.predict(X_train))}\")\n",
    "\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_BNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_BNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_BNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussNB = GaussianNB()\n",
    "GaussNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GNB = BernNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.975\n",
      "Accuracy Score of Test Set: 0.3\n",
      "F1 Score of Test Set: 0.3\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.30      1.00      0.46         9\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.10      0.33      0.15        30\n",
      "weighted avg       0.09      0.30      0.14        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, GaussNB.predict(X_train))}\")\n",
    "\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_GNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_GNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_GNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sets = ShuffleSplit(n_splits=5, test_size=.2, random_state=8)\n",
    "param_grid = {\n",
    "    'alpha': [0.25, 0.5, 1, 1.5, 2], \n",
    "    'fit_prior': [False, True]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=MultiNB,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.25, 0.5, 1, 1.5, 2],\n",
       "                         'fit_prior': [False, True]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.25, 'fit_prior': False}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9583333333333334\n",
      "Accuracy Score of Test Set: 0.9333333333333333\n",
      "F1 Score of Test Set: 0.9333333333333333\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.89      0.89      0.89         9\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "Confusion Matrix: \n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  1 10]]\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_bestNB, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.tab.txt', delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'Y'], dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = diabetes.loc[:, diabetes.columns != 'SEX']\n",
    "labels = diabetes['SEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.00</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.00</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.00</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.00</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.00</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>60</td>\n",
       "      <td>28.2</td>\n",
       "      <td>112.00</td>\n",
       "      <td>185</td>\n",
       "      <td>113.8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.9836</td>\n",
       "      <td>93</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>47</td>\n",
       "      <td>24.9</td>\n",
       "      <td>75.00</td>\n",
       "      <td>225</td>\n",
       "      <td>166.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.4427</td>\n",
       "      <td>102</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>60</td>\n",
       "      <td>24.9</td>\n",
       "      <td>99.67</td>\n",
       "      <td>162</td>\n",
       "      <td>106.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>4.1271</td>\n",
       "      <td>95</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>36</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>201</td>\n",
       "      <td>125.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.1299</td>\n",
       "      <td>85</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>36</td>\n",
       "      <td>19.6</td>\n",
       "      <td>71.00</td>\n",
       "      <td>250</td>\n",
       "      <td>133.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5951</td>\n",
       "      <td>92</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE   BMI      BP   S1     S2    S3    S4      S5   S6    Y\n",
       "0     59  32.1  101.00  157   93.2  38.0  4.00  4.8598   87  151\n",
       "1     48  21.6   87.00  183  103.2  70.0  3.00  3.8918   69   75\n",
       "2     72  30.5   93.00  156   93.6  41.0  4.00  4.6728   85  141\n",
       "3     24  25.3   84.00  198  131.4  40.0  5.00  4.8903   89  206\n",
       "4     50  23.0  101.00  192  125.4  52.0  4.00  4.2905   80  135\n",
       "..   ...   ...     ...  ...    ...   ...   ...     ...  ...  ...\n",
       "437   60  28.2  112.00  185  113.8  42.0  4.00  4.9836   93  178\n",
       "438   47  24.9   75.00  225  166.0  42.0  5.00  4.4427  102  104\n",
       "439   60  24.9   99.67  162  106.6  43.0  3.77  4.1271   95  132\n",
       "440   36  30.0   95.00  201  125.2  42.0  4.79  5.1299   85  220\n",
       "441   36  19.6   71.00  250  133.2  97.0  3.00  4.5951   92   57\n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      1\n",
       "2      2\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "437    2\n",
       "438    2\n",
       "439    2\n",
       "440    1\n",
       "441    1\n",
       "Name: SEX, Length: 442, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2, random_state=8) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, MultiNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_MNB = GaussNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_MNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_MNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_MNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.660056657223796\n",
      "Accuracy Score of Test Set: 0.6966292134831461\n",
      "F1 Score of Test Set: 0.6966292134831461\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.72      0.72        47\n",
      "           2       0.68      0.67      0.67        42\n",
      "\n",
      "    accuracy                           0.70        89\n",
      "   macro avg       0.70      0.70      0.70        89\n",
      "weighted avg       0.70      0.70      0.70        89\n",
      "\n",
      "Confusion Matrix: \n",
      " [[34 14]\n",
      " [13 28]]\n"
     ]
    }
   ],
   "source": [
    "BernNB = BernoulliNB()\n",
    "BernNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred_BNB = BernNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, BernNB.predict(X_train))}\")\n",
    "\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_BNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_BNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_BNB))\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_BNB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.6572237960339944\n",
      "Accuracy Score of Test Set: 0.7415730337078652\n",
      "F1 Score of Test Set: 0.7415730337078652\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.77      0.76        47\n",
      "           2       0.73      0.71      0.72        42\n",
      "\n",
      "    accuracy                           0.74        89\n",
      "   macro avg       0.74      0.74      0.74        89\n",
      "weighted avg       0.74      0.74      0.74        89\n",
      "\n",
      "Confusion Matrix: \n",
      " [[36 12]\n",
      " [11 30]]\n"
     ]
    }
   ],
   "source": [
    "GaussNB = GaussianNB()\n",
    "GaussNB.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, GaussNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_GNB = GaussNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_GNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_GNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_GNB))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_GNB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sets = ShuffleSplit(n_splits=5, test_size=.2, random_state=8)\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "    'fit_prior': [False, True]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=BernNB,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='f1_micro',\n",
    "                               cv=cv_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=8, test_size=0.2, train_size=None),\n",
       "             estimator=BernoulliNB(),\n",
       "             param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
       "                         'fit_prior': [False, True]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'fit_prior': False}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.6742209631728046\n",
      "Accuracy Score of Test Set: 0.6853932584269663\n",
      "F1 Score of Test Set: 0.6853932584269663\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.68      0.70        47\n",
      "           2       0.66      0.69      0.67        42\n",
      "\n",
      "    accuracy                           0.69        89\n",
      "   macro avg       0.69      0.69      0.69        89\n",
      "weighted avg       0.69      0.69      0.69        89\n",
      "\n",
      "Confusion Matrix: \n",
      " [[32 13]\n",
      " [15 29]]\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_bestNB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sets = ShuffleSplit(n_splits=5, test_size=.2, random_state=8)\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=100)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=GaussNB,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='f1',\n",
    "                               cv=cv_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=8, test_size=0.2, train_size=None),\n",
       "             estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 0.2848035868435802}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.6543909348441926\n",
      "Accuracy Score of Test Set: 0.7415730337078652\n",
      "F1 Score of Test Set: 0.7415730337078652\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.77      0.76        47\n",
      "           2       0.73      0.71      0.72        42\n",
      "\n",
      "    accuracy                           0.74        89\n",
      "   macro avg       0.74      0.74      0.74        89\n",
      "weighted avg       0.74      0.74      0.74        89\n",
      "\n",
      "Confusion Matrix: \n",
      " [[36 12]\n",
      " [11 30]]\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_bestNB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54, 19],\n",
       "       [19, 41]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_bestNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation Request:\n",
      "   This breast cancer databases was obtained from the University of Wisconsin\n",
      "   Hospitals, Madison from Dr. William H. Wolberg.  If you publish results\n",
      "   when using this database, then please include this information in your\n",
      "   acknowledgements.  Also, please cite one or more of:\n",
      "\n",
      "   1. O. L. Mangasarian and W. H. Wolberg: \"Cancer diagnosis via linear \n",
      "      programming\", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.\n",
      "\n",
      "   2. William H. Wolberg and O.L. Mangasarian: \"Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology\", \n",
      "      Proceedings of the National Academy of Sciences, U.S.A., Volume 87, \n",
      "      December 1990, pp 9193-9196.\n",
      "\n",
      "   3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: \"Pattern recognition \n",
      "      via linear programming: Theory and application to medical diagnosis\", \n",
      "      in: \"Large-scale numerical optimization\", Thomas F. Coleman and Yuying\n",
      "      Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.\n",
      "\n",
      "   4. K. P. Bennett & O. L. Mangasarian: \"Robust linear programming \n",
      "      discrimination of two linearly inseparable sets\", Optimization Methods\n",
      "      and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).\n",
      "\n",
      "1. Title: Wisconsin Breast Cancer Database (January 8, 1991)\n",
      "\n",
      "2. Sources:\n",
      "   -- Dr. WIlliam H. Wolberg (physician)\n",
      "      University of Wisconsin Hospitals\n",
      "      Madison, Wisconsin\n",
      "      USA\n",
      "   -- Donor: Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
      "      Received by David W. Aha (aha@cs.jhu.edu)\n",
      "   -- Date: 15 July 1992\n",
      "\n",
      "3. Past Usage:\n",
      "\n",
      "   Attributes 2 through 10 have been used to represent instances.\n",
      "   Each instance has one of 2 possible classes: benign or malignant.\n",
      "\n",
      "   1. Wolberg,~W.~H., \\& Mangasarian,~O.~L. (1990). Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology. In\n",
      "      {\\it Proceedings of the National Academy of Sciences}, {\\it 87},\n",
      "      9193--9196.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Collected classification results: 1 trial only\n",
      "      -- Two pairs of parallel hyperplanes were found to be consistent with\n",
      "         50% of the data\n",
      "         -- Accuracy on remaining 50% of dataset: 93.5%\n",
      "      -- Three pairs of parallel hyperplanes were found to be consistent with\n",
      "         67% of data\n",
      "         -- Accuracy on remaining 33% of dataset: 95.9%\n",
      "\n",
      "   2. Zhang,~J. (1992). Selecting typical instances in instance-based\n",
      "      learning.  In {\\it Proceedings of the Ninth International Machine\n",
      "      Learning Conference} (pp. 470--479).  Aberdeen, Scotland: Morgan\n",
      "      Kaufmann.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Applied 4 instance-based learning algorithms \n",
      "      -- Collected classification results averaged over 10 trials\n",
      "      -- Best accuracy result: \n",
      "         -- 1-nearest neighbor: 93.7%\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "      -- Also of interest:\n",
      "         -- Using only typical instances: 92.2% (storing only 23.1 instances)\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   Samples arrive periodically as Dr. Wolberg reports his clinical cases.\n",
      "   The database therefore reflects this chronological grouping of the data.\n",
      "   This grouping information appears immediately below, having been removed\n",
      "   from the data itself:\n",
      "\n",
      "     Group 1: 367 instances (January 1989)\n",
      "     Group 2:  70 instances (October 1989)\n",
      "     Group 3:  31 instances (February 1990)\n",
      "     Group 4:  17 instances (April 1990)\n",
      "     Group 5:  48 instances (August 1990)\n",
      "     Group 6:  49 instances (Updated January 1991)\n",
      "     Group 7:  31 instances (June 1991)\n",
      "     Group 8:  86 instances (November 1991)\n",
      "     -----------------------------------------\n",
      "     Total:   699 points (as of the donated datbase on 15 July 1992)\n",
      "\n",
      "   Note that the results summarized above in Past Usage refer to a dataset\n",
      "   of size 369, while Group 1 has only 367 instances.  This is because it\n",
      "   originally contained 369 instances; 2 were removed.  The following\n",
      "   statements summarizes changes to the original Group 1's set of data:\n",
      "\n",
      "   #####  Group 1 : 367 points: 200B 167M (January 1989)\n",
      "   #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\n",
      "   #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\n",
      "   #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\n",
      "   #####                  : Changed 0 to 1 in field 6 of sample 1219406\n",
      "   #####                  : Changed 0 to 1 in field 8 of following sample:\n",
      "   #####                  : 1182404,2,3,1,1,1,2,0,1,1,1\n",
      "\n",
      "5. Number of Instances: 699 (as of 15 July 1992)\n",
      "\n",
      "6. Number of Attributes: 10 plus the class attribute\n",
      "\n",
      "7. Attribute Information: (class attribute has been moved to last column)\n",
      "\n",
      "   #  Attribute                     Domain\n",
      "   -- -----------------------------------------\n",
      "   1. Sample code number            id number\n",
      "   2. Clump Thickness               1 - 10\n",
      "   3. Uniformity of Cell Size       1 - 10\n",
      "   4. Uniformity of Cell Shape      1 - 10\n",
      "   5. Marginal Adhesion             1 - 10\n",
      "   6. Single Epithelial Cell Size   1 - 10\n",
      "   7. Bare Nuclei                   1 - 10\n",
      "   8. Bland Chromatin               1 - 10\n",
      "   9. Normal Nucleoli               1 - 10\n",
      "  10. Mitoses                       1 - 10\n",
      "  11. Class:                        (2 for benign, 4 for malignant)\n",
      "\n",
      "8. Missing attribute values: 16\n",
      "\n",
      "   There are 16 instances in Groups 1 to 6 that contain a single missing \n",
      "   (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
      "\n",
      "9. Class distribution:\n",
      " \n",
      "   Benign: 458 (65.5%)\n",
      "   Malignant: 241 (34.5%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/breast-cancer-wisconsin.names\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/breast-cancer-wisconsin.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[data[6] != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 11)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1: -1]\n",
    "y = data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace(2, 0)\n",
    "y = y.replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "694    0\n",
       "695    0\n",
       "696    1\n",
       "697    1\n",
       "698    1\n",
       "Name: 10, Length: 683, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 9)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.8992673992673993\n",
      "Accuracy Score of Test Set: 0.927007299270073\n",
      "F1 Score of Test Set: 0.927007299270073\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        84\n",
      "           1       0.96      0.85      0.90        53\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.91      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Confusion Matrix: \n",
      " [[82  8]\n",
      " [ 2 45]]\n"
     ]
    }
   ],
   "source": [
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, MultiNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_MNB = MultiNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_MNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_MNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_MNB))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_MNB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9542124542124543\n",
      "Accuracy Score of Test Set: 0.9854014598540146\n",
      "F1 Score of Test Set: 0.9854014598540146\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        84\n",
      "           1       0.98      0.98      0.98        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "Confusion Matrix: \n",
      " [[83  1]\n",
      " [ 1 52]]\n"
     ]
    }
   ],
   "source": [
    "GaussNB = GaussianNB()\n",
    "GaussNB.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, GaussNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_GNB = GaussNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_GNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_GNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "\n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_GNB))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_GNB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.6593406593406593\n",
      "Accuracy Score of Test Set: 0.6131386861313869\n",
      "F1 Score of Test Set: 0.6131386861313869\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        84\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.61       137\n",
      "   macro avg       0.31      0.50      0.38       137\n",
      "weighted avg       0.38      0.61      0.47       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "BernNB = BernoulliNB()\n",
    "BernNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred_BNB = BernNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, BernNB.predict(X_train))}\")\n",
    "\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_BNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_BNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_BNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_sets = ShuffleSplit(n_splits=5, test_size=.2, random_state=8)\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=100)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=GaussNB,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='f1',\n",
    "                               cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.31...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 0.1}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9633699633699634\n",
      "Accuracy Score of Test Set: 0.9927007299270073\n",
      "F1 Score of Test Set: 0.9927007299270073\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        84\n",
      "           1       1.00      0.98      0.99        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "Confusion Matrix: \n",
      " [[84  1]\n",
      " [ 0 52]]\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_pred_bestNB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def prepare_train_test(self, test_size=0.2, random_state=8):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    def MultinomialNB(self):\n",
    "        MultiNB = MultinomialNB()\n",
    "        MultiNB.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        print(f\"Accuracy Score of Training Set:  {accuracy_score(self.y_train, MultiNB.predict(self.X_train))}\")\n",
    "\n",
    "        y_pred_MNB = MultiNB.predict(self.X_test)\n",
    "        print(f\"Accuracy Score of Test Set: {accuracy_score(self.y_test, y_pred_MNB)}\")\n",
    "\n",
    "        f1 = f1_score(self.y_test, y_pred_MNB, average='weighted')\n",
    "        print(f\"F1 Score of Test Set: {f1}\")\n",
    "\n",
    "        print(\"Classification Report\")    \n",
    "        print(classification_report(self.y_test, y_pred_MNB))\n",
    "        \n",
    "    def GaussianNB(self):\n",
    "        GaussNB = GaussianNB()\n",
    "        GaussNB.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(f\"Accuracy Score of Training Set:  {accuracy_score(self.y_train, GaussNB.predict(self.X_train))}\")\n",
    "\n",
    "        y_pred_GNB = GaussNB.predict(self.X_test)\n",
    "        print(f\"Accuracy Score of Test Set: {accuracy_score(self.y_test, y_pred_GNB)}\")\n",
    "\n",
    "        f1 = f1_score(self.y_test, y_pred_GNB, average='micro')\n",
    "        print(f\"F1 Score of Test Set: {f1}\")\n",
    "\n",
    "        print(\"Classification Report\")    \n",
    "        print(classification_report(self.y_test, y_pred_GNB))\n",
    "        \n",
    "    def BernoulliNB(self):\n",
    "        BernNB = BernoulliNB()\n",
    "        BernNB.fit(self.X_train, self.y_train)\n",
    "        print(f\"Accuracy Score of Training Set:  {accuracy_score(self.y_train, BernNB.predict(self.X_train))}\")\n",
    "\n",
    "        y_pred_BNB = BernNB.predict(self.X_test)\n",
    "        print(f\"Accuracy Score of Test Set: {accuracy_score(self.y_test, y_pred_BNB)}\")\n",
    "\n",
    "        f1 = f1_score(self.y_test, y_pred_BNB, average='micro')\n",
    "        print(f\"F1 Score of Test Set: {f1}\")\n",
    "\n",
    "        print(\"Classification Report\")    \n",
    "        print(classification_report(self.y_test, y_pred_BNB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
